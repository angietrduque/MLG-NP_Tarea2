}
Vector_of_Means
plot(seq(1,50), Vector_of_Means, xlab = "Sample Size", ylab = "Centimeters")
abline(h=mu, col="blue")
mu=4
sigma=0.3
Vector_of_Means <- rep(0,1000)
Vector_of_Means
Vector_of_Means[1]<-mean(rnorm(1,mean=mu,sd=sigma))
Vector_of_Means
Vector_of_Means[1]<-mean(rnorm(1,mean=mu,sd=sigma))
for (i in 2:length(Vector_of_Means)) {
Vector_of_Means[i] <- mean(rnorm(i, mean=mu, sd=sigma))
}
Vector_of_Means
plot(seq(1,50), Vector_of_Means, xlab = "Sample Size", ylab = "Centimeters")
abline(h=mu, col="blue")
Vector_of_Means
plot(seq(1,1000), Vector_of_Means, xlab = "Sample Size", ylab = "Centimeters")
abline(h=mu, col="blue")
mu=4
sigma=0.3
Vector_of_Means <- rep(0,1000)
Vector_of_Means
Vector_of_Means[1]<-mean(rnorm(1,mean=mu,sd=sigma))
for (i in 2:length(Vector_of_Means)) {
Vector_of_Means[i] <- (rnorm(i, mean=mu, sd=sigma))
}
Vector_of_Means
plot(seq(1,1000), Vector_of_Means, xlab = "Sample Size", ylab = "Centimeters")
abline(h=mu, col="blue")
Variable1 <- replicate(n = 1000, rnorm(6, 4, 0.3), simplify = F )
Variable1
tabla<-matrix(nrow=1000,ncol=6)
tabla<-data.frame(tabla)
for ( i in 1:370 ) {
tabla[i,] <- Variable1[[i]]
}
for ( i in 1:1000 ) {
tabla[i,] <- Variable1[[i]]
}
print(tabla)
View(tabla)
write.csv(tabla, file="Prueba1.csv")
Variable1 <- replicate(n = 1000, rnorm(6, 4, 0.3), simplify = F )
plot(Variable1[[1]], ylim = c(2,5))
plot(Variable1[[1]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
plot(Variable1[[2]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
plot(Variable1[[i]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
plot(Variable1[[i]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
plot(Variable1[[i]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
plot(Variable1[[i]], ylim = c(2,5))
for ( i in 1:1000 ) {
plot(Variable1[[i]], ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
}
View(tabla)
plot(Variable1, ylim = c(2,5))
abline(h=3.297783271, lty=2, col="red") # inferior
abline(h=4.702216729, lty=2, col="blue") # superior
# Distribucion beta
n =10000
alfa = 5.7424
beta = 76.2932
Simulacion <- rbeta(n,alfa,beta)
curve(Simulacion,col="blue",lwd=2,xlab="x",ylab="f(x)")
x <- rbeta(n,alfa,beta)
curve(x,col="blue",lwd=2,xlab="x",ylab="f(x)")
hist(x)
Simulacion <- rbeta(n,alfa,beta)
hist(x)
plot(density(x))
plot(density(Simulacion), xlab = "", ylab = "", main = "")
x <- rbeta(n,alfa,beta)
Simulacion <- data.frame(x)
View(Simulacion)
individuos <- c(1:10000)
Simulacion <- data.frame(individuos,x)
suppressMessages(library(gplots))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
ggplot(Simulacion,aes(x=individuos,y=x)) + geom_bar(stat = "identity",color="white")
ggplot(Simulacion,aes(x=individuos,y=x)) + geom_histogram()
ggplot(Simulacion,aes(x=x)) + geom_histogram()
ggplot(Simulacion,aes(x=x)) + geom_density()
G1 <- ggplot(Simulacion,aes(x=x)) + geom_histogram()
G2 <- ggplot(Simulacion,aes(x=x)) + geom_density()
grid.arrange(G1,G2, nrow = 1)
G1 <- ggplot(Simulacion,aes(x=x)) + geom_histogram() + theme_classic()
G2 <- ggplot(Simulacion,aes(x=x)) + geom_density() + theme_classic()
grid.arrange(G1,G2, nrow = 1)
suppressMessages(library(gplots))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
# Distribucion beta
n =10000
alfa = 5.7
beta = 76.1
x <- rbeta(n,alfa,beta)
individuos <- c(1:10000)
Simulacion <- data.frame(individuos,x)
G1 <- ggplot(Simulacion,aes(x=x)) + geom_histogram() + theme_classic()
G2 <- ggplot(Simulacion,aes(x=x)) + geom_density() + theme_classic()
grid.arrange(G1,G2, nrow = 1)
# Distribucion beta
n =10000
alfa = 5.74
beta = 76.29
x <- rbeta(n,alfa,beta)
individuos <- c(1:10000)
Simulacion <- data.frame(individuos,x)
G1 <- ggplot(Simulacion,aes(x=x)) + geom_histogram() + theme_classic()
G2 <- ggplot(Simulacion,aes(x=x)) + geom_density() + theme_classic()
G2
alfa = 5.74
beta = 76.29
alfa1 = 12.83
beta1 = 184.61
x1 <- rbeta(n,alfa1,beta1)
G3 <- ggplot(Simulacion,aes(x=x1)) + geom_density() + theme_classic()
G3
grid.arrange(G2,G3, nrow = 1)
col <- readOGR(dsn="/Users/cesar.saavedra/Downloads/gadm36_COL_shp",layer="COL_adm1")
install.packages("readOGR")
library(ggplot2)
library(ggmap)
install.packages("ggmap")
library(ggmap)
qmap("Cali", zoom = 10)
install.packages("GADMTools")
library(GADMTools)
COL <- gadm_sf_loadCountries(c("COL"), level=0, basefile="./")
COL
gadm_plot(COL)
DEPTOS <- gadm_sf_loadCountries(c("COL"), level = 1, basefile = "./")
gadm_plot(DEPTOS)
Valle <- gadm_subset(DEPTOS, level=1, regions="Valle")
gadm_plot(Valle) %>% gadm_showNorth("tl") %>% gadm_showScale("bl")
listNames(DEPTOS, 1)
Valle <- gadm_subset(DEPTOS, level=1, regions="Valle del Cauca")
gadm_plot(Valle) %>% gadm_showNorth("tl") %>% gadm_showScale("bl")
listNames(MUNICIPIOS, 2)
MUNICIPIOS <- gadm_sf_loadCountries(c("COL"), level = 2, basefile = "./")
gadm_plot(MUNICIPIOS)
listNames(MUNICIPIOS, 2)
library(readxl)
Datos <- read_excel("Desktop/Clase 8-10-20/Datos.xlsx")
View(Datos)
Datos <- as.factor(Datos)
Datos
library(readxl)
Datos <- read_excel("Desktop/Clase 8-10-20/Datos.xlsx")
Comuna <- as.factor(Datos$Comuna)
Comuna <- as.factor(Datos$Comuna)
A2017 <- as.numeric(Datos$2017)
A2018 <- as.numeric(Datos$2018)
Homicidios <- data.frame(Comuna, A2017, A2018)
A2017 <- as.numeric(Datos$2017)
A2017 <- as.numeric(Datos$2017)
Comuna <- as.factor(Datos$Comuna)
A17 <- as.numeric(Datos$2017)
Datos <- read_excel("Desktop/Clase 8-10-20/Datos.xlsx")
View(Datos)
Comuna <- as.factor(Datos$Comuna)
A17 <- as.numeric(Datos$A17)
A18 <- as.numeric(Datos$A18)
Homicidios <- data.frame(Comuna, A2017, A2018)
Homicidios
Homicidios <- data.frame(Comuna, A17, A18)
Homicidios
summary(Homicidios)
ggplot(Homicidios, aes(Comuna, A17)) + geom_boxplot()
ggplot(Homicidios, aes(Comuna, A17)) + geom_bar()
ggplot(Homicidios, aes(Comuna, A17)) + geom_histogram()
ggplot(Homicidios, aes(Comuna, A17)) + geom_point()
ggplot(Homicidios, aes(y=Comuna, x=A17)) + geom_point()
ggplot(Homicidios, aes(y=Comuna, x=A17)) + geom_boxplot()
# Load libraries ----------------------------------------------------------
require(pacman)
pacman::p_load(raster, rgdal, rgeos, gtools, tidyverse)
# Load data ---------------------------------------------------------------
mps <- shapefile('./shp/mpios_geo_ok.shp')
# Load data ---------------------------------------------------------------
mps <- shapefile('./shp/mpios_geo_ok.shp')
# Load data ---------------------------------------------------------------
mps <- shapefile("/Users/cesar.saavedra/Documents/Emprendimiento/Mapas/mpios_geo_ok.shp")
dpt <- aggregate(mps, 'NOMBRE_DPT')
lbl <- data.frame(month_abb = month.abb, mes = 1:12)
# Selecting only Valle del Cauca ------------------------------------------
mps <- mps[mps@data$NOMBRE_DPT %in% 'VALLE DEL CAUCA',]
vll <- aggregate(mps, 'COD_DEPTO')
# Extract by mask ---------------------------------------------------------
prec <- raster::getData('worldclim',
var = 'prec',
res = 0.5,
lon = coordinates(vll)[1],
lat = coordinates(vll)[2])
prec <- raster::crop(prec, vll) %>%
raster::mask(., vll)
# Load data ---------------------------------------------------------------
mps <- shapefile("/Users/cesar.saavedra/Documents/Emprendimiento/Mapas/mpios_geo_ok.shp")
dpt <- aggregate(mps, 'NOMBRE_DPT')
lbl <- data.frame(month_abb = month.abb, mes = 1:12)
plot(mps)
# Selecting only Valle del Cauca ------------------------------------------
mps <- mps[mps@data$NOMBRE_DPT %in% 'VALLE DEL CAUCA',]
vll <- aggregate(mps, 'COD_DEPTO')
# Extract by mask ---------------------------------------------------------
prec <- raster::getData('worldclim',
var = 'prec',
res = 0.5,
lon = coordinates(vll)[1],
lat = coordinates(vll)[2])
coordinates(vll)[2]
lon = coordinates(vll)[1],
lat = coordinates(vll)[2])
coordinates(vll)[1]
prec <- raster::crop(prec, vll) %>%
raster::mask(., vll)
# Making the map ----------------------------------------------------------
vls <- rasterToPoints(prec) %>%
as_tibble() %>%
gather(var, value, -x, -y) %>%
mutate(mes = parse_number(var)) %>%
inner_join(., lbl, by = 'mes') %>%
dplyr::select(x, y, month_abb, value) %>%
mutate(month_abb = factor(month_abb, levels = month.abb))
vls %>%
filter(month_abb == 'Jan')
summary(vls$value)
gg <- ggplot(vls)  +
geom_tile(aes(x = x, y =  y, fill = value)) +
facet_wrap(~ month_abb) +
scale_fill_gradientn(colours = RColorBrewer::brewer.pal(n = 8, name = "GnBu"),
na.value = 'white', limits = c(0, 1000), breaks = seq(0, 1000, 200)) +
geom_polygon(data = mps, aes(x=long, y = lat, group = group), color = 'grey', fill='NA') +
geom_polygon(data = dpt, aes(x=long, y = lat, group = group), color = 'grey', fill='NA') +
theme_bw() +
scale_x_continuous(breaks = c(-78, -77, -76, -75)) +
coord_equal(xlim = extent(vll)[1:2], ylim = extent(vll)[3:4]) +
labs(title = 'PrecipitaciÃ³n mensual - Valle del Cauca', fill = 'mm',  x = 'Longitud', y = 'Latitud') +
theme(legend.position = 'bottom',
plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.key.width = unit(5, 'line')) +
guides(shape = guide_legend(override.aes = list(size = 10)))
gg
View(prec)
gg <- ggplot(vls)  +
geom_tile(aes(x = x, y =  y, fill = value)) +
facet_wrap(~ month_abb) +
scale_fill_gradientn(colours = RColorBrewer::brewer.pal(n = 8, name = "GnBu"),
na.value = 'white', limits = c(0, 1000), breaks = seq(0, 1000, 200)) +
geom_polygon(data = mps, aes(x=long, y = lat, group = group), color = 'grey', fill='NA') +
geom_polygon(data = dpt, aes(x=long, y = lat, group = group), color = 'grey', fill='NA') +
theme_bw() +
scale_x_continuous(breaks = c(-78, -77, -76, -75)) +
coord_equal(xlim = extent(vll)[1:2], ylim = extent(vll)[3:4]) +
labs(title = 'PrecipitaciÃ³n mensual - Valle del Cauca 2019', fill = 'mm',  x = 'Longitud', y = 'Latitud') +
theme(legend.position = 'bottom',
plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.key.width = unit(5, 'line')) +
guides(shape = guide_legend(override.aes = list(size = 10)))
gg
knitr::opts_chunk$set(echo = FALSE)
suppressMessages(library(deSolve))
suppressMessages(library(nlme))
suppressMessages(library(ggplot2))
suppressMessages(library(plotly))
suppressMessages(library(reshape2))
# https://rpubs.com/juanhklopper/Nonlinear-modeling-Intro-to-R-Modeling-Series
Ks <- c(100, 200, 150)
n0 <- c(5, 5, 6)
r <- c(0.15, 0.2, 0.15)
time <- 1:50
logF <- function(time, K, n0, r){
d <- K * n0 * exp(r*time) / (K + n0 * (exp(r*time) - 1))
return(d)
}
set.seed(123)
dat <- data.frame(Group = character(),
Time = numeric(),
Count = numeric())
for(i in 1:3){
Ab <- logF(time = time, K = Ks[i], n0 = n0[i], r = r[i])
tmp <- data.frame(Group = paste0("G", i), Time = time,
Count = Ab + rnorm(time, 0, 5))
dat <-rbind(dat, tmp)
}
plot_ly(data = dat,
x = ~Time,
y = ~Count,
color = ~Group,
type = "scatter",
mode = "markers") %>% layout(title = "Growth over time for three groups",
yaxis = list(zeroline = F))
#------------------------------------------------------------#
setwd("/Users/cesar.saavedra/Documents/Emprendimiento/WordCloud")
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text = iconv(text, to="ASCII//TRANSLIT")
text
corpus <- Corpus(VectorSource(text))
suppressMessages(library(tm))
suppressMessages(library(SnowballC))
suppressMessages(library(wordcloud))
suppressMessages(library(wordcloud2))
suppressMessages(library(RColorBrewer))
suppressMessages(library(RCurl))
suppressMessages(library(XML))
suppressMessages(library("htmlwidgets"))
suppressMessages(library(webshot))
webshot::install_phantomjs()
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text = iconv(text, to="ASCII//TRANSLIT")
text
corpus <- Corpus(VectorSource(text))
d  <- tm_map(corpus, tolower)
d  <- tm_map(d, stripWhitespace)
d <- tm_map(d, removePunctuation)
d <- tm_map(d, removeNumbers)
stopwords("spanish")
d <- tm_map(d, removeWords, stopwords("spanish"))
tdm <- TermDocumentMatrix(d)
findFreqTerms(tdm, lowfreq=0)
m <- as.matrix(tdm) #lo vuelve una matriz
v <- sort(rowSums(m),decreasing=TRUE) #lo ordena y suma
df <- data.frame(word = names(v),freq=v)
barplot(df[1:10,]$freq, las = 2, names.arg = df[1:10,]$word,
col ="lightblue", main ="", ylab = "Frecuencia de palabras")
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=1000, random.order=T, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud2(data=df, size = 0.7, shape = 'pentagon',color="random-dark",backgroundColor="black")
wordcloud2(df, color = "random-dark",size = 0.8, shape = "circle", backgroundColor = "white")
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text = iconv(text, to="ASCII//TRANSLIT")
text
corpus <- Corpus(VectorSource(text))
d  <- tm_map(corpus, tolower)
d  <- tm_map(d, stripWhitespace)
d <- tm_map(d, removePunctuation)
d <- tm_map(d, removeNumbers)
stopwords("spanish")
d <- tm_map(d, removeWords, stopwords("spanish"))
tdm <- TermDocumentMatrix(d)
findFreqTerms(tdm, lowfreq=0)
m <- as.matrix(tdm) #lo vuelve una matriz
v <- sort(rowSums(m),decreasing=TRUE) #lo ordena y suma
df <- data.frame(word = names(v),freq=v)
barplot(df[1:10,]$freq, las = 2, names.arg = df[1:10,]$word,
col ="lightblue", main ="", ylab = "Frecuencia de palabras")
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=1000, random.order=T, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud2(data=df, size = 0.7, shape = 'pentagon',color="random-dark",backgroundColor="black")
wordcloud2(df, color = "random-dark",size = 0.8, shape = "circle", backgroundColor = "white")
# Make the graph
my_graph <- wordcloud2(data=df, size = 0.7, shape = 'pentagon',color="random-dark", backgroundColor="white")
# save it in html
saveWidget(my_graph,"tmp.html",selfcontained = F)
# and in png or pdf
webshot("tmp.html","fig_1.png", delay =5, vwidth = 480, vheight=480)
letterCloud(data=df, word = "T", color="white", backgroundColor="pink")
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text <- readLines(filePath,encoding="UTF-8")
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text = iconv(text, to="ASCII//TRANSLIT")
text
corpus <- Corpus(VectorSource(text))
d  <- tm_map(corpus, tolower)
d  <- tm_map(d, stripWhitespace)
d <- tm_map(d, removePunctuation)
d <- tm_map(d, removeNumbers)
stopwords("spanish")
d <- tm_map(d, removeWords, stopwords("spanish"))
tdm <- TermDocumentMatrix(d)
findFreqTerms(tdm, lowfreq=0)
m <- as.matrix(tdm) #lo vuelve una matriz
v <- sort(rowSums(m),decreasing=TRUE) #lo ordena y suma
df <- data.frame(word = names(v),freq=v)
barplot(df[1:10,]$freq, las = 2, names.arg = df[1:10,]$word,
col ="lightblue", main ="", ylab = "Frecuencia de palabras")
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=1000, random.order=T, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud2(data=df, size = 0.7, shape = 'pentagon',color="random-dark",backgroundColor="black")
wordcloud2(df, color = "random-dark",size = 0.8, shape = "circle", backgroundColor = "white")
# Make the graph
my_graph <- wordcloud2(data=df, size = 0.7, shape = 'pentagon',color="random-dark", backgroundColor="white")
# save it in html
saveWidget(my_graph,"tmp.html",selfcontained = F)
# and in png or pdf
webshot("tmp.html","fig_1.png", delay =5, vwidth = 480, vheight=480)
letterCloud(data=df, word = "T", color="white", backgroundColor="pink")
#------------------------------------------------------------#
#cargar datos
filePath <- "Datos.txt"
text <- readLines(filePath,encoding="UTF-8")
text = iconv(text, to="ASCII//TRANSLIT")
text
corpus <- Corpus(VectorSource(text))
d  <- tm_map(corpus, tolower)
d  <- tm_map(d, stripWhitespace)
d <- tm_map(d, removePunctuation)
d <- tm_map(d, removeNumbers)
stopwords("spanish")
d <- tm_map(d, removeWords, stopwords("spanish"))
tdm <- TermDocumentMatrix(d)
findFreqTerms(tdm, lowfreq=0)
m <- as.matrix(tdm) #lo vuelve una matriz
v <- sort(rowSums(m),decreasing=TRUE) #lo ordena y suma
df <- data.frame(word = names(v),freq=v)
barplot(df[1:10,]$freq, las = 2, names.arg = df[1:10,]$word,
col ="lightblue", main ="", ylab = "Frecuencia de palabras")
wordcloud2(df, color = "random-dark",size = 0.8, shape = "circle", backgroundColor = "white")
barplot(df[1:10,]$freq, las = 2, names.arg = df[1:10,]$word,
col ="lightblue", main ="", ylab = "Frecuencia de palabras")
setwd("/Users/cesar.saavedra/Documents/GitHub/MLG-NP_Tarea2")
#----------------------------------------------------------------------------------------#
# Actividad 2
#----------------------------------------------------------------------------------------#
# Cargar los datos
Datos <- read.table("Datos.txt",header=T,sep = ",")
Datos
View(Datos)
dim(Datos)
names(Datos)
str(Datos)
describe(Datos)
# Estadisticas descriptivas
summary(Datos)
# Variable indicadora: pHi
summary(Datos[,"pH"])
rango = (max(Datos$pH)-min(Datos$pH))/3
a = min(Datos$pH); a
b = a + rango; b
c = b + rango; c
d = c + rango; d
pHi <- vector()
pHi[Datos$pH < b] <- "Bajo"
pHi[Datos$pH >= b & Datos$pH < c] <- "Medio"
pHi[Datos$pH > c] <- "Alto"
pHi <- as.factor(pHi)
table(pHi)
library(VGAM)
install.packages(c("VGAM", "MASS"))
library(MASS)
library(VGAM)
fit = vglm(quality ~ fixed.acidity + pHi, data = Datos, family = cumulative(parallel = TRUE))
summary(fit)
fixed.acidity
summary(fit)
View(Datos)
dim(Datos)
Datos$quality
summary(Datos$quality)
suppressMessages(library(dplyr))
suppressMessages(library(readxl))
suppressMessages(library(tidyverse))
suppressMessages(library(FactoMineR))
suppressMessages(library(factoextra))
suppressMessages(library(foreign))
suppressMessages(library(corrplot))
suppressMessages(library(polycor))
suppressMessages(library(psych))
suppressMessages(library(gplots))
suppressMessages(library(gridExtra))
suppressMessages(library(viridis))
suppressMessages(library(lsr))
suppressMessages(library(DescTools))
suppressMessages(library(magrittr))
suppressMessages(library(nlme))
suppressMessages(library(MASS))
suppressMessages(library(multilevel))
suppressMessages(library(reshape))
suppressMessages(library(homals))
suppressMessages(library(GGally))
suppressMessages(library(CCA))
suppressMessages(library(plotly))
suppressMessages(library(broom))
suppressMessages(library(readr))
suppressMessages(library(readxl))
summary(fit)
